{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2575423e-4bc4-4595-bf0c-f4242d0bbf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c344f1db-4486-4b10-a3ef-831ed0ba783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  face_landmarks_list = detection_result.face_landmarks\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected faces to visualize.\n",
    "  for idx in range(len(face_landmarks_list)):\n",
    "    face_landmarks = face_landmarks_list[idx]\n",
    "\n",
    "    # Draw the face landmarks.\n",
    "    face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    face_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n",
    "    ])\n",
    "\n",
    "    mp.solutions.drawing_utils.draw_landmarks(\n",
    "        image=annotated_image,\n",
    "        landmark_list=face_landmarks_proto,\n",
    "        connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp.solutions.drawing_styles\n",
    "        .get_default_face_mesh_tesselation_style())\n",
    "    mp.solutions.drawing_utils.draw_landmarks(\n",
    "        image=annotated_image,\n",
    "        landmark_list=face_landmarks_proto,\n",
    "        connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n",
    "          landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp.solutions.drawing_styles\n",
    "          .get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1dbe39cf-d03a-4fb2-bcb4-a24765763e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"face_landmarker.task\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12edad8d-bbc4-43b2-8d59-e300281dcdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W20230906 15:49:36.063767 13108636 face_landmarker_graph.cc:168] Face blendshape model contains CPU only ops. Sets FaceBlendshapesGraph acceleration to Xnnpack.\n"
     ]
    }
   ],
   "source": [
    "BaseOptions = mp.tasks.BaseOptions\n",
    "FaceLandmarker = mp.tasks.vision.FaceLandmarker\n",
    "FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "options = FaceLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.IMAGE)\n",
    "\n",
    "detector = FaceLandmarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9f43e26-2eec-4548-ac76-5f8fa5a3b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image)\n",
    "    face_landmarker_result = detector.detect(mp_image)\n",
    "    annotated_image = draw_landmarks_on_image(image, face_landmarker_result)\n",
    "\n",
    "    cv2.imshow('frame', annotated_image)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40f8b68e-32b4-4e1a-95e3-0f61deea4a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed emotion:angry\n",
      "completed emotion:disgust\n",
      "completed emotion:fear\n",
      "completed emotion:happy\n",
      "completed emotion:neutral\n",
      "completed emotion:sad\n",
      "completed emotion:surprise\n",
      "Completed all emotion\n"
     ]
    }
   ],
   "source": [
    "directory_image_path = \"emotion-dataset\"\n",
    "\n",
    "emotion = [\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    "emotion_cords_dataset = list()\n",
    "for dir_emotion in emotion:\n",
    "    dir_emotion_path = f\"{directory_image_path}/{dir_emotion}\"\n",
    "    \n",
    "    file_names = [file for file in os.listdir(dir_emotion_path) if os.path.isfile(os.path.join(dir_emotion_path, file))]\n",
    "\n",
    "    data_cord_emotion = list()\n",
    "\n",
    "    for image in file_names:\n",
    "        img = cv2.imread(f\"{dir_emotion_path}/{image}\")\n",
    "        \n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=img)\n",
    "        face_landmarker_result = detector.detect(mp_image)\n",
    "        if len(face_landmarker_result.face_landmarks) == 0:\n",
    "            continue\n",
    "        face_landmarker_result = face_landmarker_result.face_landmarks[0]\n",
    "        \n",
    "        cords_image = list(map(lambda landmark_xyz: [landmark_xyz.x, landmark_xyz.y, landmark_xyz.z], face_landmarker_result))\n",
    "\n",
    "        data_cord_emotion.append(cords_image)\n",
    "    emotion_cords_dataset.append(data_cord_emotion)\n",
    "    \n",
    "    print(f'completed emotion:{dir_emotion}')\n",
    "print('Completed all emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8bfeb-3db4-47b4-8095-38d3eb258675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
